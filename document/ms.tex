\documentclass[12pt,preprint]{aastex}

% has to be before amssymb it seems
\usepackage{color,hyperref}
\definecolor{linkcolor}{rgb}{0,0,0.5}
\hypersetup{colorlinks=true,linkcolor=linkcolor,citecolor=linkcolor,
            filecolor=linkcolor,urlcolor=linkcolor}

\usepackage{url}
\usepackage{algorithmic,algorithm}
\usepackage{amssymb,amsmath}

\newcommand{\arxiv}[1]{\href{http://arxiv.org/abs/#1}{arXiv:#1}}

\usepackage{listings}
\definecolor{lbcolor}{rgb}{0.9,0.9,0.9}
\lstset{ %
    language=Python,
    basicstyle=\footnotesize\ttfamily,
    showspaces=false,
    showstringspaces=false,
    tabsize=2,
    breaklines=false,
    breakatwhitespace=true,
    identifierstyle=\ttfamily,
    keywordstyle=\bfseries\color[rgb]{0.133,0.545,0.133},
    commentstyle=\color[rgb]{0.133,0.545,0.133},
    stringstyle=\color[rgb]{0.627,0.126,0.941},
}

\newcommand{\project}[1]{{\sffamily #1}}
\newcommand{\paper}{document}
\newcommand{\license}{MIT License}

\newcommand{\foreign}[1]{\emph{#1}}
\newcommand{\etal}{\foreign{et\,al.}}
\newcommand{\etc}{\foreign{etc.}}

\newcommand{\Fig}[1]{Figure~\ref{fig:#1}}
\newcommand{\fig}[1]{\Fig{#1}}
\newcommand{\figlabel}[1]{\label{fig:#1}}
\newcommand{\Tab}[1]{Table~\ref{tab:#1}}
\newcommand{\tab}[1]{\Tab{#1}}
\newcommand{\tablabel}[1]{\label{tab:#1}}
\newcommand{\Eq}[1]{Equation~(\ref{eq:#1})}
\newcommand{\eq}[1]{\Eq{#1}}
\newcommand{\eqlabel}[1]{\label{eq:#1}}
\newcommand{\Sect}[1]{Section~\ref{sect:#1}}
\newcommand{\sect}[1]{\Sect{#1}}
\newcommand{\App}[1]{Appendix~\ref{sect:#1}}
\newcommand{\app}[1]{\App{#1}}
\newcommand{\sectlabel}[1]{\label{sect:#1}}
\newcommand{\Algo}[1]{Algorithm~\ref{algo:#1}}
\newcommand{\algo}[1]{\Algo{#1}}
\newcommand{\algolabel}[1]{\label{algo:#1}}

% math symbols
\newcommand{\dd}{\,\mathrm{d}}
\newcommand{\bvec}[1]{\boldsymbol{#1}}
\newcommand{\paramvector}[1]{\bvec{#1}}
\DeclareMathOperator*{\argmax}{arg\,max}

% other symbols
\newcommand{\bin}{\ensuremath{\hat{w}}}

\begin{document}

\title{How to make a histogram of noisy data}

\newcommand{\nyu}{2}
\newcommand{\mpia}{3}
\author{Daniel~Foreman-Mackey\altaffilmark{1,\nyu},
        David~W.~Hogg\altaffilmark{\nyu,\mpia},
        other losers?}
\altaffiltext{1}{To whom correspondence should be addressed:
                 \url{danfm@nyu.edu}}
\altaffiltext{\nyu}{Center for Cosmology and Particle Physics,
                    Department of Physics, New York University,
                    4 Washington Place, New York, NY, 10003, USA}
\altaffiltext{\mpia}{Max-Planck-Institut f\"ur Astronomie,
                     K\"onigstuhl 17, D-69117 Heidelberg, Germany}

\begin{abstract}
Dude.
\end{abstract}

\keywords{}

\section{Introduction}

\section{The Problem}

A histogram with bin edges $\bvec{\bin}$ and normalized bin heights
$\bvec{\theta}$ for some quantity $w$ can be written as the probability
density
\begin{eqnarray}
p(w\,|\,\bvec{\bin},\,\bvec{\theta}) &=& \left\{\begin{array}{ll}
\theta_1, & \mathrm{if}\,\bin_0 \le w < \bin_1 \\
\theta_2, & \mathrm{if}\,\bin_1 \le w < \bin_2 \\
\multicolumn{2}{c}{\cdots} \\
\theta_L, & \mathrm{if}\,\bin_{L-1} \le w < \bin_L\\
0 & \mathrm{otherwise}
\end{array}\right. \quad.
\end{eqnarray}
In practice, a single observation $k$ of $w$ is conditioned on some data
$\bvec{x}_k$.
In general, this constraint is given by a posterior probability density
$p(w_k\,|\,\bvec{x}_k,\,\bvec{\alpha})$ that is---or can be---represented as
a set of $N$ samples
\begin{eqnarray}\eqlabel{posts}
w_k^{(n)} &\sim& p(w_k\,|\,\bvec{x}_k,\,\bvec{\alpha}) \quad.
\end{eqnarray}

We'll leave the discussion of the choice of bin edges to another time and for
now just find the best fit bin heights.

In the above situation, there is no closed form solution for ``the best''
histogram of $w$ given the observations $\bvec{x}$.
In order to make this question quantitative, let's consider the
\emph{marginalized likelihood function}
\begin{eqnarray}\eqlabel{marglike}
p(\{\bvec{x}_k\}\,|\,\bvec{\theta}) &=&
\prod_{k=1}^K\int p(w_k,\,\bvec{x}_k\,|\,\bvec{\theta})\dd w_k \\
&=&
\prod_{k=1}^K\int p(w_k,\,|\,\bvec{\theta})\,p(\bvec{x}_k\,|\,w_k)\dd w_k
\quad.
\end{eqnarray}
This function quantifies the probability of all observations given a
particular set of bin heights.
This question becomes a constrained optimization problem
\begin{eqnarray}\eqlabel{argmax}
\bvec{\theta}_\star &=&
\argmax_{\bvec{\theta}} \log p(\{\bvec{x}_k\}\,|\,\bvec{\theta})
\end{eqnarray}
under the constraint
\begin{eqnarray}
\int p(w\,|\,\bvec{\theta}) &=& 1
\end{eqnarray}
or, equivalently
\begin{eqnarray}
\sum_{l=1}^L (\bin_l - \bin_{l-1})\,\theta_l &=& 1 \quad.
\end{eqnarray}

The key here is to be able to compute \eq{marglike} efficiently given our
constraints on $w_k$ (\eq{posts}).
To do this, we can simplify \eq{marglike} as follows
\begin{eqnarray}
p(\{\bvec{x}_k\}\,|\,\bvec{\theta}) &=&
\prod_{k=1}^K\int p(w_k,\,|\,\bvec{\theta})\,p(\bvec{x}_k\,|\,w_k) \,
\frac{p(w_k\,|\,\bvec{x}_k,\,\bvec{\alpha})}
     {p(w_k\,|\,\bvec{x}_k,\,\bvec{\alpha})}
\dd w_k \\
&=&
\prod_{k=1}^K\int
\frac{p(w_k\,|\,\bvec{\theta})}
     {p(w_k\,|\,\bvec{\alpha})} \,
p(\bvec{x}_k\,|\,\bvec{\alpha})\,
p(w_k\,|\,\bvec{x}_k,\,\bvec{\alpha})
\dd w_k
\end{eqnarray}
giving
\begin{eqnarray}
\frac{p(\{\bvec{x}_k\}\,|\,\bvec{\theta})}{p(\{\bvec{x}_k\}\,|\,\bvec{\alpha})}
&\approx&
\prod_{k=1}^K \frac{1}{N_k} \sum_{n=1}^{N_k}
\frac{p(w_k^{(n)}\,|\,\bvec{\theta})}
     {p(w_k^{(n)}\,|\,\bvec{\alpha})}
\quad.
\end{eqnarray}


\acknowledgments It is a pleasure to thank
\ldots
for helpful contributions to the ideas and code presented here.

\begin{thebibliography}{}\raggedright

\bibitem[Foreman-Mackey \etal(2013)]{emcee}
Foreman-Mackey, D., Hogg, D.~W., Lang, D., \& Goodman, J.\ 2013,
\pasp, 125, 306

\end{thebibliography}

\end{document}
